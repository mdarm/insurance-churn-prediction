{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "Xb3NWgYnBMYw",
        "PBxePyeihxNY",
        "hkVRox2EBLsd",
        "EDDgFE83lXlB",
        "T0O0JnbGnUXX",
        "XIEWN-pAnp-X"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Oracle's churn-insurance dataset\n",
        "\n",
        "Click to run on colab (if you are not already there): [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1Vg3894R2ljhG8zMaf24RUn6mLryXfncS?usp=sharing)\n",
        "\n",
        "\n",
        "This notebook contains a solution to the churn-insurance challenge, as presented by Oracle, during the AI Hackathon in Athens.\n"
      ],
      "metadata": {
        "id": "Xb3NWgYnBMYw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown --id 10K5-CAAZb5wIf-WkCTgQo0Xi_xdDFC_h\n",
        "!curl -L 'https://docs.google.com/spreadsheets/d/11C3RLM1vhL8idoCPwhK6ALRxCFShXesg/export?format=xlsx' -o data-dictionary.xlsx"
      ],
      "metadata": {
        "id": "uibUIcqe_L7F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert xlsx file to csv prior to opening it with Pandas."
      ],
      "metadata": {
        "id": "Xp9bh4J7jR8G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt update -y\n",
        "!sudo apt install gnumeric\n",
        "!ssconvert ml_churn_final_data.xlsx dataset.csv"
      ],
      "metadata": {
        "id": "D3cvlLrEG0dU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preliminary settings"
      ],
      "metadata": {
        "id": "PBxePyeihxNY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Libraries"
      ],
      "metadata": {
        "id": "xZb2TgWuh6Vn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "#pd.set_option('precision', 3)\n",
        "\n",
        "# Data Visualisation Libraries\n",
        "import matplotlib.pyplot as plt\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "\n",
        "import seaborn as sns\n",
        "sns.set_style('darkgrid')\n",
        "\n",
        "# Statistics\n",
        "from scipy.stats import chi2_contingency\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Machine Learning\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
        "from sklearn.model_selection import learning_curve\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, auc, roc_auc_score, roc_curve\n",
        "from sklearn.metrics import confusion_matrix\n"
      ],
      "metadata": {
        "id": "xmNfs2xbCdfa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Global (visual) settings"
      ],
      "metadata": {
        "id": "GpKgaJtch_28"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "font_size = 20\n",
        "plt.rcParams['axes.labelsize'] = font_size\n",
        "plt.rcParams['axes.titlesize'] = font_size + 2\n",
        "plt.rcParams['xtick.labelsize'] = font_size - 2\n",
        "plt.rcParams['ytick.labelsize'] = font_size - 2\n",
        "plt.rcParams['legend.fontsize'] = font_size - 2\n",
        "\n",
        "colors = ['#DD403A', '#00A5E0']\n",
        "colors_cat = ['#E8907E', '#D5CABD', '#7A6F86', '#C34A36', '#B0A8B9', '#845EC2', '#8f9aaa', '#FFB86F', '#63BAAA', '#9D88B3', '#38c4e3']\n",
        "colors_comp = ['steelblue', 'seagreen', 'black', 'darkorange', 'purple', 'firebrick', 'slategrey']\n",
        "\n",
        "random_state = 42\n",
        "scoring_metric = 'recall'\n",
        "comparison_dict, comparison_test_dict = {}, {}"
      ],
      "metadata": {
        "id": "GcSH3i6PiAOC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Helper functions"
      ],
      "metadata": {
        "id": "1AURWshMiQoi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_continuous(feature):\n",
        "    '''Plot a histogram and boxplot for the churned and retained distributions for the specified feature.'''\n",
        "    df_func = data.copy()\n",
        "    df_func['POLICY_STATUS'] = df_func['POLICY_STATUS'].astype('category')\n",
        "\n",
        "    fig, (ax1, ax2) = plt.subplots(2,\n",
        "                                   figsize=(9, 7),\n",
        "                                   sharex=True,\n",
        "                                   gridspec_kw={'height_ratios': (.7, .3)})\n",
        "\n",
        "    for df, color, label in zip([df_retained, df_churned], colors, ['Churned', 'Retained']):\n",
        "        sns.histplot(data=df,\n",
        "                     x=feature,\n",
        "                     bins=15,\n",
        "                     color=color,\n",
        "                     alpha=0.66,\n",
        "                     edgecolor='firebrick',\n",
        "                     label=label,\n",
        "                     kde=False,\n",
        "                     ax=ax1)\n",
        "    ax1.legend()\n",
        "\n",
        "    sns.boxplot(x=feature, y='POLICY_STATUS', data=df_func, palette=colors, ax=ax2)\n",
        "    ax2.set_ylabel('')\n",
        "    ax2.set_yticklabels(['Churned', 'Retained'])\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "\n",
        "def plot_conf_mx(cm, ax):\n",
        "    '''Plot a confusion matrix in the specified axes object.'''\n",
        "    sns.heatmap(data=cm,\n",
        "                annot=True,\n",
        "                cmap='Blues',\n",
        "                annot_kws={'fontsize': 30},\n",
        "                ax=ax)\n",
        "\n",
        "    ax.set_xlabel('Predicted Label')\n",
        "    ax.set_xticks([0.5, 1.5])\n",
        "    ax.set_xticklabels(['Churned', 'Retained'])\n",
        "\n",
        "    ax.set_ylabel('True Label')\n",
        "    ax.set_yticks([0.25, 1.25])\n",
        "    ax.set_yticklabels(['Churned', 'Retained'])\n",
        "\n",
        "\n",
        "def plot_learning_curve(estimator,\n",
        "                        X,\n",
        "                        y,\n",
        "                        ax,\n",
        "                        cv=None,\n",
        "                        train_sizes=np.linspace(0.1, 1.0, 5)):\n",
        "    '''Plot the learning curves for an estimator in the specified axes object.'''\n",
        "    train_sizes, train_scores, test_scores = learning_curve(\n",
        "        estimator,\n",
        "        X,\n",
        "        y,\n",
        "        cv=cv,\n",
        "        n_jobs=-1,\n",
        "        train_sizes=train_sizes,\n",
        "        scoring='accuracy')\n",
        "\n",
        "    train_scores_mean = np.mean(train_scores, axis=1)\n",
        "    train_scores_std = np.std(train_scores, axis=1)\n",
        "    test_scores_mean = np.mean(test_scores, axis=1)\n",
        "    test_scores_std = np.std(test_scores, axis=1)\n",
        "\n",
        "    ax.fill_between(train_sizes,\n",
        "                    train_scores_mean - train_scores_std,\n",
        "                    train_scores_mean + train_scores_std,\n",
        "                    alpha=0.1,\n",
        "                    color='dodgerblue')\n",
        "    ax.fill_between(train_sizes,\n",
        "                    test_scores_mean - test_scores_std,\n",
        "                    test_scores_mean + test_scores_std,\n",
        "                    alpha=0.1,\n",
        "                    color='darkorange')\n",
        "\n",
        "    ax.plot(train_sizes,\n",
        "            train_scores_mean,\n",
        "            color='dodgerblue',\n",
        "            marker='o',\n",
        "            linestyle='-',\n",
        "            label='Training Score')\n",
        "    ax.plot(train_sizes,\n",
        "            test_scores_mean,\n",
        "            color='darkorange',\n",
        "            marker='o',\n",
        "            linestyle='-',\n",
        "            label='Cross-validation Score')\n",
        "\n",
        "    ax.set_xlabel('Training Examples')\n",
        "    ax.set_ylabel('Score')\n",
        "    ax.legend(loc='best', fontsize=14)\n",
        "\n",
        "\n",
        "def clf_performance(classifier, classifier_name, classifier_name_abv):\n",
        "    '''Display the overall performance of a classifier with this template.'''\n",
        "    print('\\n', classifier_name)\n",
        "    print('-------------------------------')\n",
        "    print('   Best Score ({}): '.format(scoring_metric) + str(np.round(classifier.best_score_, 3)))\n",
        "    print('   Best Parameters: ')\n",
        "    for key, value in classifier.best_params_.items():\n",
        "        print('      {}: {}'.format(key, value))\n",
        "\n",
        "    y_pred_pp = cross_val_predict(estimator=classifier.best_estimator_,\n",
        "                                  X=X_train,\n",
        "                                  y=y_train,\n",
        "                                  cv=5,\n",
        "                                  method='predict_proba')[:, 1]\n",
        "    y_pred = y_pred_pp.round()\n",
        "\n",
        "    cm = confusion_matrix(y_train, y_pred, normalize='true')\n",
        "\n",
        "    fpr, tpr, _ = roc_curve(y_train, y_pred_pp)\n",
        "    comparison_dict[classifier_name_abv] = [\n",
        "        accuracy_score(y_train, y_pred),\n",
        "        precision_score(y_train, y_pred),\n",
        "        recall_score(y_train, y_pred),\n",
        "        roc_auc_score(y_train, y_pred_pp), fpr, tpr\n",
        "    ]\n",
        "\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "    plot_conf_mx(cm, ax1)\n",
        "    plot_learning_curve(classifier.best_estimator_, X_train, y_train, ax2)\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "\n",
        "def plot_feature_imp(classifier, classifier_name, color, ax):\n",
        "    '''Plot the importance of features for a classifier as a barplot.'''\n",
        "    importances = pd.DataFrame({'Feature': X_train.columns,\n",
        "                                'Importance': np.round(classifier.best_estimator_.feature_importances_, 3)})\n",
        "\n",
        "    importances = importances.sort_values('Importance', ascending=True).set_index('Feature')\n",
        "\n",
        "    importances.plot.barh(color=color,\n",
        "                          edgecolor='firebrick',\n",
        "                          legend=False,\n",
        "                          ax=ax)\n",
        "    ax.set_title(classifier_name)\n",
        "    ax.set_xlabel('Importance')\n",
        "\n",
        "\n",
        "def test_func(classifier, classifier_name, ax):\n",
        "    '''Assess the performance on the test set and plot the confusion matrix.'''\n",
        "    y_pred = classifier.predict(X_test)\n",
        "    cm = confusion_matrix(y_test, y_pred, normalize='true')\n",
        "\n",
        "    comparison_test_dict[classifier_name] = [accuracy_score(y_test, y_pred),\n",
        "                                             precision_score(y_test, y_pred),\n",
        "                                             recall_score(y_test, y_pred)]\n",
        "\n",
        "    sns.heatmap(cm,\n",
        "                annot=True,\n",
        "                annot_kws={'fontsize': 24},\n",
        "                cmap='Blues',\n",
        "                ax=ax)\n",
        "\n",
        "    ax.set_title(classifier_name)\n",
        "\n",
        "    ax.set_xlabel('Predicted Label')\n",
        "    ax.set_xticks([0.5, 1.5])\n",
        "    ax.set_xticklabels(['Retained', 'Churned'])\n",
        "\n",
        "    ax.set_ylabel('True Label')\n",
        "    ax.set_yticks([0.2, 1.4])\n",
        "    ax.set_yticklabels(['Retained', 'Churned'])"
      ],
      "metadata": {
        "id": "G3yQM7gXiRBN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import dataset and perform some preprocessing"
      ],
      "metadata": {
        "id": "hkVRox2EBLsd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"dataset.csv\", parse_dates=[\"SYMB_END\", \"MHNET\"])"
      ],
      "metadata": {
        "id": "8E7gw_ushQ3q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.head())"
      ],
      "metadata": {
        "id": "bYOZKlG_D0oO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.info())"
      ],
      "metadata": {
        "id": "0TR3RdlxEu9Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.describe())\n",
        "#print(df.select(pl.all().exclude(pl.datatypes.Object)).describe())"
      ],
      "metadata": {
        "id": "zduvfrliHqPV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Missing values in each column"
      ],
      "metadata": {
        "id": "jEguCJCQFHrZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.isnull().sum())\n",
        "#print(df.select([pl.sum(pl.col(column).is_null()).alias(column) for column in df.columns]))"
      ],
      "metadata": {
        "id": "Rqx4VuBVEvVf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Number of unique values in each column"
      ],
      "metadata": {
        "id": "zhH1MYURE55N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.nunique())\n",
        "#print(df.select([pl.col(column).n_unique().alias(column) for column in df.columns]))"
      ],
      "metadata": {
        "id": "cdRHCCl8FD57"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['MHNET_DATE'] = pd.to_datetime(df['MHNET'], format='%Y%m')\n",
        "df['SYMB_END'] = pd.to_datetime(df['SYMB_END'])\n",
        "df['DAYS_TO_END'] = (df['SYMB_END'] - df['MHNET_DATE']).dt.days\n",
        "#filtered_df = df[(df['DAY_DIFF'] >= 58)]\n",
        "df = df.drop(columns=['MHNET_DATE'])"
      ],
      "metadata": {
        "id": "1nvaaBMtkzYT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = df\n",
        "data.isnull().sum()"
      ],
      "metadata": {
        "id": "zcnWuXfrk4Jr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = data.drop_duplicates()"
      ],
      "metadata": {
        "id": "MWoRCfW4k6lE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There exists a class imbalance."
      ],
      "metadata": {
        "id": "I_kZohxqlFgl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(figsize=(6, 6))\n",
        "\n",
        "sns.countplot(x='POLICY_STATUS', data=data, palette=colors, ax=ax)\n",
        "\n",
        "ax.set_xticklabels(['Churned', 'Retained'])\n",
        "ax.set_xlabel('Status')\n",
        "ax.set_ylabel('Count')"
      ],
      "metadata": {
        "id": "Xovpx6YulBEx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_churned = data[data['POLICY_STATUS'] == 0]\n",
        "df_retained = data[data['POLICY_STATUS'] == 1]\n",
        "\n",
        "plot_continuous('DAYS_TO_END')"
      ],
      "metadata": {
        "id": "JNvT1xIOlLMd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature selection"
      ],
      "metadata": {
        "id": "EDDgFE83lXlB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "All features"
      ],
      "metadata": {
        "id": "9uy3vudwmtWe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "categorical = [\n",
        "    'ACCEPT_EMAIL', 'CEPAG', 'CAR_USAGE', 'POLICY_STATUS', 'EIDOS_PER',\n",
        "    'LOYALTY_PROGRAM', 'IS_STANDING_ORDER', 'HAS_RETURNED',\n",
        "    'CAR_BRAND', 'ACCEPT_SMS', 'TROPOS_EXOFL', 'INS_PACKAGE',\n",
        "    'TAXK_INC_ZONE_NAME', 'GENDER', 'CAR_MODEL', 'IS_RENEWAL',\n",
        "    'AGENT_CATG', 'CAR_INVC_ZONE', 'BONUS_MALUS', 'NEW_PREMIUM', 'OLD_PREMIUM'\n",
        "]\n",
        "\n",
        "continuous = [\n",
        "    'NUM_COVERAGES', 'CLAIMS_AMOUNT', 'NUM_ACCIDENTS_RESP',\n",
        "    'NUM_ACCIDENTS_RESP_FR', 'SYMB_DURATION', 'NUM_ACTIVE_SYMB',\n",
        "    'NUM_ACCIDENTS_RESP_NOT_FR', 'CAR_PROD_YEAR', 'PENDING_AMOUNT',\n",
        "    'DISCOUNT_AMOUNT', 'CAR_AGE',\n",
        "    'ASFAL_AMOUNT', 'TOTAL_YEAR_INSURED_SYMB', 'CAR_CAPACITY',\n",
        "    'PREMIUM_PRICE', 'NUM_COMPLAINTS', 'NUM_ACCIDENTS_NOT_RESP',\n",
        "    'LOSS_RATIO', 'PAID_AMOUNT', 'CUST_BIRTH_DATE', 'SYMB_START',\n",
        "    'SYMB_END', 'NEW_PREMIUM_PRICE', 'CUST_ZIP_CODE', 'NUM_ACCIDENTS_INVOLVED',\n",
        "    'PAYMENT_END', 'RENEWAL_SYMB', 'NUM_VEHICLES', 'DAYS_TO_END'\n",
        "]\n",
        "\n",
        "assert not set(categorical) & set(continuous), \"Reality check.\""
      ],
      "metadata": {
        "id": "O4SJ0nsPmvTg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preliminary feature-drop."
      ],
      "metadata": {
        "id": "D9F91KOaliA3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Has NaN values across almost the whole dataset\n",
        "data = data.drop(columns=[\"TRPLHR\"])\n",
        "\n",
        "# Reference date and contract number are not required\n",
        "data = data.drop(columns=[\"MHNET\", \"SYMB\"])\n",
        "\n",
        "# Do not need customer code\n",
        "data = data.drop(columns=[\"CUSTOMER\"])\n",
        "\n",
        "# Remove all agent ids\n",
        "data = data.drop(columns=[\"AGENT_CD\", \"CDIE_AGENT_CD\", \"CGD_AGENT_CD\",\n",
        "                          \"CEMP_AGENT_CD\", \"CEP3_AGENT_CD\"]\n",
        "                )"
      ],
      "metadata": {
        "id": "JcngCG6DlRxU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Drop some categorical features\n",
        "\n",
        "High-level intuition.\n",
        "\n",
        "`LOYALTY_PROGRAM`: Indicates customer engagement; high engagement reduces churn risk.\n",
        "\n",
        "`IS_RENEWAL`: At renewal, customers decide to stay or leave, crucial for churn prediction.\n",
        "\n",
        "`HAS_RETURNED`: Returning customers may have different loyalty and satisfaction levels.\n",
        "\n",
        "`CAR_USAGE`: Influences the perceived value of service, affecting churn."
      ],
      "metadata": {
        "id": "SU2-HGr_l1mC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "retained_categorical = [\n",
        "    'LOYALTY_PROGRAM',\n",
        "    'IS_RENEWAL',\n",
        "    'HAS_RETURNED',\n",
        "    'CAR_USAGE'\n",
        "]\n",
        "\n",
        "dropped_categorical = [\n",
        "    'ACCEPT_EMAIL',\n",
        "    'CEPAG',\n",
        "    'CAR_BRAND',\n",
        "    'ACCEPT_SMS',\n",
        "    'TROPOS_EXOFL',\n",
        "    'INS_PACKAGE',\n",
        "    'TAXK_INC_ZONE_NAME',\n",
        "    'GENDER',\n",
        "    'CAR_MODEL',\n",
        "    'AGENT_CATG',\n",
        "    'CAR_INVC_ZONE',\n",
        "    'BONUS_MALUS',\n",
        "    'NEW_PREMIUM',\n",
        "    'OLD_PREMIUM',\n",
        "    'EIDOS_PER',\n",
        "    'IS_STANDING_ORDER'\n",
        "]"
      ],
      "metadata": {
        "id": "VwA-ueaalkw_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = data.drop(dropped_categorical, axis=1)"
      ],
      "metadata": {
        "id": "r7ClmmhPmL_u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Keep only month aspect from dates."
      ],
      "metadata": {
        "id": "eNxio9UPmRQF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data['CUST_BIRTH_DATE'] = pd.to_datetime(data['CUST_BIRTH_DATE'], errors='coerce').dt.year\n",
        "data['SYMB_START'] = pd.to_datetime(data['SYMB_START'], errors='coerce').dt.month\n",
        "data['SYMB_END'] = pd.to_datetime(data['SYMB_END'], errors='coerce').dt.month\n",
        "data['PAYMENT_END'] = pd.to_datetime(data['PAYMENT_END'], errors='coerce').dt.month\n",
        "data['RENEWAL_SYMB'] = pd.to_datetime(data['RENEWAL_SYMB'], errors='coerce').dt.month"
      ],
      "metadata": {
        "id": "lMS5MKtEmQte"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = data.dropna()"
      ],
      "metadata": {
        "id": "VdcvOb73mW2m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scale continuous features"
      ],
      "metadata": {
        "id": "YCOWysivmhNA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "\n",
        "data[continuous] = scaler.fit_transform(data[continuous])"
      ],
      "metadata": {
        "id": "JQN-LjqamavE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_data = data['POLICY_STATUS']\n",
        "X_data = data.drop(columns=['POLICY_STATUS'])"
      ],
      "metadata": {
        "id": "cHXgHqVOmyrJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_data.shape, y_data.shape)"
      ],
      "metadata": {
        "id": "-ivutkBzm3V9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split train/test."
      ],
      "metadata": {
        "id": "WbyYyF3dm91B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data,\n",
        "                                                    test_size=0.2,\n",
        "                                                    random_state=random_state)"
      ],
      "metadata": {
        "id": "xOpP_LSbm5ej"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Address class imbalance\n",
        "\n",
        "Used SMOTE ('Synthetic Minority Oversampling Technique') algorithm, which 'finds a record that is similar to the record being upsampled and creates a synthetic record that is a randomly weighted average of the original record and the neighbouring record, where the weight is generated separately for each predictor'\n",
        "\n",
        "*Practical Statistics for Data Scientists*, 2nd Edition, by Peter Bruce, Andrew Bruce, and Peter Gedeck (2020)"
      ],
      "metadata": {
        "id": "o8l0mqVBnGDd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "over = SMOTE(sampling_strategy='auto', random_state=random_state)\n",
        "X_train, y_train = over.fit_resample(X_train, y_train)\n",
        "\n",
        "y_train.value_counts()"
      ],
      "metadata": {
        "id": "2iepWtbdnCBx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Models"
      ],
      "metadata": {
        "id": "T0O0JnbGnUXX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Logistic Regression"
      ],
      "metadata": {
        "id": "xAiCw5A3nYd9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr = LogisticRegression(random_state=random_state)\n",
        "\n",
        "param_grid = {\n",
        "    'max_iter': [100],\n",
        "    'penalty': ['l1', 'l2'],\n",
        "    'C': [0.001, 0.01, 0.1, 1],\n",
        "    'solver': ['lbfgs', 'liblinear']\n",
        "}\n",
        "\n",
        "lr_clf = GridSearchCV(estimator=lr,\n",
        "                      param_grid=param_grid,\n",
        "                      scoring=scoring_metric,\n",
        "                      cv=5,\n",
        "                      verbose=False,\n",
        "                      n_jobs=-1)\n",
        "\n",
        "best_lr_clf = lr_clf.fit(X_train, y_train)\n",
        "clf_performance(best_lr_clf, 'Logistic Regression', 'LR')"
      ],
      "metadata": {
        "id": "4zJWJqNwnQWS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Random Forest"
      ],
      "metadata": {
        "id": "zRPXYFX9nbG1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf = RandomForestClassifier(random_state=random_state)\n",
        "param_grid = {\n",
        "    'n_estimators': [40],\n",
        "    'criterion': ['entropy', 'gini'],\n",
        "    'max_depth': [6],\n",
        "    'bootstrap': [True, False],\n",
        "    'min_samples_split': [2, 5],\n",
        "    'min_samples_split': [2, 3, 5]\n",
        "}\n",
        "\n",
        "rf_clf = GridSearchCV(estimator=rf,\n",
        "                      param_grid=param_grid,\n",
        "                      scoring=scoring_metric,\n",
        "                      cv=5,\n",
        "                      verbose=False,\n",
        "                      n_jobs=-1)\n",
        "\n",
        "best_rf_clf = rf_clf.fit(X_train, y_train)\n",
        "clf_performance(best_rf_clf, 'Random Forest', 'RF')"
      ],
      "metadata": {
        "id": "-nKoCo6unbie"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LGBMClassifier\n"
      ],
      "metadata": {
        "id": "8CJCiHGHncCe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lgbmc = LGBMClassifier(random_state=random_state)\n",
        "\n",
        "param_grid = {\n",
        "    'max_depth': [10],\n",
        "    'num_leaves': [6],\n",
        "    'learning_rate': [0.001, 0.01, 0.1],\n",
        "    'n_estimators': [100],\n",
        "    'feature_fraction': [0.5],\n",
        "    'min_child_samples': [5, 10],\n",
        "    'reg_alpha': [0.1, 0.5],\n",
        "    'reg_lambda': [0.1, 0.5],\n",
        "    'device': ['gpu']\n",
        "}\n",
        "\n",
        "lgbmc_clf = GridSearchCV(estimator=lgbmc,\n",
        "                         param_grid=param_grid,\n",
        "                         scoring=scoring_metric,\n",
        "                         cv=5,\n",
        "                         verbose=False,\n",
        "                         n_jobs=-1)\n",
        "\n",
        "best_lgbmc_clf = lgbmc_clf.fit(X_train, y_train)\n",
        "clf_performance(best_lgbmc_clf, 'LGBMClassifier', 'LGBMC')"
      ],
      "metadata": {
        "id": "UnY2XzwdndJu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature importance of tree-methods"
      ],
      "metadata": {
        "id": "nPeM09oWoEow"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "colors_fi = ['steelblue', 'darkgray']\n",
        "\n",
        "fig = plt.subplots(1, 2, figsize=(12, 24))\n",
        "\n",
        "for i, (name, clf) in enumerate(zip(['RF', 'LGBM'],\n",
        "                                    [best_rf_clf, best_lgbmc_clf])):\n",
        "\n",
        "    ax = plt.subplot(2, 2, i + 1)\n",
        "    plot_feature_imp(clf, name, colors_fi[i], ax)\n",
        "    plt.ylabel('')\n",
        "\n",
        "plt.tight_layout();"
      ],
      "metadata": {
        "id": "07B2VWd1oHpz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ensembling and Testing"
      ],
      "metadata": {
        "id": "XIEWN-pAnp-X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tuned_voting_soft.fit(X_train, y_train)\n",
        "\n",
        "fig, ax = plt.subplots(4, 1, figsize=(8, 18))\n",
        "\n",
        "for i, (name, clf) in enumerate(zip(['LR', 'RF', 'LGBM', 'SVot'],\n",
        "                                    [best_lr_clf.best_estimator_,\n",
        "                                     best_rf_clf.best_estimator_,\n",
        "                                     best_lgbmc_clf.best_estimator_,\n",
        "                                     tuned_voting_soft])):\n",
        "    test_func(clf, name, ax=ax[i])\n",
        "\n",
        "plt.tight_layout()"
      ],
      "metadata": {
        "id": "x67_qBG5nsZY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}